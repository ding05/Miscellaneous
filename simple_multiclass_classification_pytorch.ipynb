{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classify 100 numbers into five categories.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8fPrz3-U-h7"
      },
      "source": [
        "# Classify 100 numbers into Five Categories\n",
        "\n",
        "by Ding\n",
        "\n",
        "This notebook shows how to use a neural network for a (simple) classification problem. (We know this could be done by a few lines of code.)\n",
        "\n",
        "We want machine to learn to classify [0, 0.2) into Class 0, [0.2, 0.4) into Class 1, [0.4, 0.6) into Class 2, [0.6, 0.8) into Class 3 and [0.8, 1) into Class 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA9VySlbU9DK"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as Data\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNDRBfMYbg5S",
        "outputId": "f78a8bee-421e-462d-f4c9-e91b474961ad"
      },
      "source": [
        "nums = np.arange(1, 101)\n",
        "nums"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
              "        14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,\n",
              "        27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,\n",
              "        40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,\n",
              "        53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,\n",
              "        66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,\n",
              "        79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,  91,\n",
              "        92,  93,  94,  95,  96,  97,  98,  99, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 224
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU9CHuOObsnx"
      },
      "source": [
        "nums_1 = nums.reshape(100, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlkRbN12b02j"
      },
      "source": [
        "def normalize(x):\n",
        "    x1 = x - min(x)\n",
        "    x2 = max(x) - min(x)\n",
        "    return x1/x2\n",
        "\n",
        "nums_norm = normalize(nums_1) # No need to normalize it?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNf5u1A3b7OB"
      },
      "source": [
        "labels = np.zeros([100,1])\n",
        "\n",
        "labels[20:40] = 1\n",
        "labels[40:60] = 2\n",
        "labels[60:80] = 3\n",
        "labels[80:100] = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioafrjPzRHwU"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(nums_norm, labels, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqHLfQ0jEEMJ"
      },
      "source": [
        "x_train = torch.from_numpy(x_train).type(torch.FloatTensor)\n",
        "x_test = torch.from_numpy(x_test).type(torch.FloatTensor)\n",
        "y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
        "y_test = torch.from_numpy(y_test).type(torch.LongTensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "558NLrpPOXk7"
      },
      "source": [
        "y_train = torch.squeeze(y_train) # It has to fit the dimension.\n",
        "y_test = torch.squeeze(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqPxBR2yEWvX"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(1,8)\n",
        "        self.fc2 = nn.Linear(8,5)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.tanh(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "              \n",
        "    def predict(self,x):\n",
        "        pred = F.softmax(self.forward(x))\n",
        "        pred = pred.tolist()\n",
        "        ans = []\n",
        "        for t in pred:\n",
        "          ans.append(t.index(max(t))) # Find the position (index) of the largest probability among the five predicted probabilities\n",
        "        return torch.tensor(ans)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8LMEyZqEWx6"
      },
      "source": [
        "model = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8t5-GWuEtCg",
        "outputId": "91d62ff6-0fec-4444-85b1-22e6c02d4790"
      },
      "source": [
        "epochs = 200\n",
        "losses = []\n",
        "for i in range(epochs):\n",
        "    y_pred = model.forward(x_train)\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    losses.append(loss.item())\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbAY9jWJEW0T",
        "outputId": "10064cbd-9e23-4a71-f804-6d88de08c83e"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print(\"Observation:\")\n",
        "print(y_test)\n",
        "print(\"Prediction:\")\n",
        "print(model.predict(x_test))\n",
        "\n",
        "print(\"Accuracy:\")\n",
        "print(accuracy_score(model.predict(x_test), y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Observation:\n",
            "tensor([4, 3, 0, 3, 4, 0, 3, 2, 1, 0, 3, 4, 4, 0, 0, 1, 0, 0, 1, 2])\n",
            "Prediction:\n",
            "tensor([4, 2, 0, 3, 4, 0, 3, 2, 1, 0, 3, 4, 4, 0, 0, 1, 0, 0, 1, 2])\n",
            "Accuracy:\n",
            "0.95\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1794: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}